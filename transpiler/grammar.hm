# TODO: can we define the grammar in the terms below, but then create a finite state machine
# which reads in the grammar below, deduces the possible states, then reads tokens in and
# flips between states while reading through files?

# list of elements that can compose the grammar.
# doesn't include tokens like `starts_upper_case` or `starts_lower_case`,
# which comprise the grammar but don't specify it.
grammar_element: one_of[
    Statement: one_of[
        Variable_definition
        Variable_declaration
        Function_definition
        Function_declaration
        Class_declaration
        Expression
    ]
    Expression: {
        token Prefix_unary_operator?
        one_of[Binary_expression, Number, Array[nestable]]
        token Postfix_unary_operator?
    }
    Binary_expression: {
        token Binary_operator
        Left_operand: expression
        Right_operand: expression
    }
    Nestable: one_of[Function_call, Plain_type, Variable_name]

    Type: one_of[Plain_type, Variable_declaration, Function_declaration]

    # e.g., `my_class` or `generic_class[type1, ...]`
    Plain_type: {Class_name, Generic_specification?}
    # e.g., `My_class` or `Generic_class[type1, ...]` for a type that's in scope
    Default_named_variable: {Default_class_name, Generic_specification?}

    # e.g., `[x, y: constraint_y, Z: z_type]`
    # to be valid, `x` should not be in scope.
    Generic_declaration: array[Argument_declaration]
    # e.g., `[x, y: int, Z: 5]`
    # to be valid, `x` *should* be in scope.
    Generic_specification: array[Argument_definition]

    Variable_name: token variable_case
    Variable_declaration: one_of[Standard_variable_declaration, Abbreviated_variable_declaration]
    Standard_variable_declaration: {Variable_name, token Declaration, Plain_type}
    Abbreviated_variable_declaration: {Default_named_variable, token Declaration?}

    Variable_definition: one_of[Standard_variable_definition, Abbreviated_variable_definition]
    Standard_variable_definition: {Variable_name, token Declaration, Expression}
    Abbreviated_variable_definition: {Default_named_variable, token Declaration, Expression}

    Function_name
    Function_args_with_return_type
    # e.g., `my_fn(Arg1, Arg2): type` or `fn[type1](Arg1, Arg2): type`
    # can be used as a `Type` when returning a function from another function.
    Function_declaration
    Function_definition
    Function_call

    Argument_declaration
    Argument_definition

    Rhs_statement
    Atomic_statement

    Class_name: token snake_case 
    Default_class_name: token variable_case
    Class_definition
    Class_statement
    Class_method

    For_loop

    End_of_input
]
# TODO: `grammar_element`s probably should be POD structs, e.g., `Type: {Array[Token]}`
# however, it's probably better to give them more individualized types, like
# `Type: one_of[Plain_type: {Name: str, Generics?}, Function_declaration: {...}]`

Grammar: {
    element: grammar_element
    statement: grammar_element statement
    parsed: array[statement] {
        ::hm(): array[str]
            # TODO!
            []
        ::execute(Interpreter;): hm[ok: any, uh: str]
            # TODO
            uh("not implemented")
    }
    uh: {
        Bad_line: index
        Error: str
        Parsed
    }
    hm[of]: hm[ok: of, uh]
    result: hm[parsed]

    ::parse(File): result
        Context;
        I parse(File, Context;)

    ::parse(File, Context;): result
        Proposals;
        what I parse(File read(), Context, Proposals;)
            Parsed:
                File write(Parsed hm())
                Context commit(Proposals)
            Uh:
                error("on line $(Uh Bad_line + 1):")
                if Uh Bad_line > 0
                    error(". $(Lines[Uh Bad_line - 1]")
                error("> $(Lines[Uh Bad_line]")
                error("? $(Uh Error)")
                File open("w", (Handle):
                    for Index; < Lines count()
                        Handle write(Lines[Index])
                        if Index == Uh Bad_line
                            Handle write(Uh Error)
                )

    ::parse(Array[str]., Context;): result
        Proposals;
        I parse(Array!, Context, Proposals;) check((Ok):
            Context commit(Proposals!)
        )
    
    @private
    ::parse(Array[str]., Context, Proposals;): result
        # TODO: can we do `Tokenizer(...);` to define `Tokenizer: tokenizer(...)`?
        Tokenizer; tokenizer(Array!)

        Parsed;
        for Index; < Array count()
            # TODO: Tokens should be retrieved as needed
            #       probably need a `Tokenizer; {Line_index: index, Column_index: index, Array[str]}`
            #       class which has some methods like `next()`
            Tokens: tokenize(Array[Index], Context, Proposals) map((Uh):
                {Bad_line: Index, Error: Uh, Parsed!}
            ) assert()
            Parsed append(I parse(Tokens, Context, Proposals;) map((Uh):
                {Bad_line: Index, Error: Uh, Parsed!}
            ) assert())
        Parsed

    @protected
    ::parse(Array[token], Context, Proposals;): 

    @private
    Lot[at: element, token_matcher]: [
        Type: one_of_matcher([
            Function_declaration
            Plain_type
        ])
        Plain_type: sequence_matcher([
            token snake_case
            optional_matcher(Generics_list)
        ])

        Variable_name: single_token_matcher(Variable_case)
        Variable_declaration: sequence_matcher([
            Variable_name
            optional_matcher(operator_matcher("?"))
            one_of_matcher([operator_matcher(":"), operator_matcher(";")])
            Type_element
        ])
        Variable_definition: sequence_matcher([
            Variable_name
            optional_matcher(operator_matcher("?"))
            one_of_matcher([operator_matcher(":"), operator_matcher(";")])
            Rhs_statement
        ])

        Function_name: single_token_matcher(Snake_case)
        Function_declaration: one_of_matcher([
            # `fn_name(Args): ret_type`, `fn_name?(Args): ret_type`, or
            # `fn_name(Args)?: ret_type`, also allowing `;` instead of `:`.
            sequence_matcher([
                Function_name
                Function_args_with_return_type
            ])
            # `fn_name: fn(Args): ret_type` or similar
            sequence_matcher([
                Function_name
                one_of_matcher([operator_matcher(":"), operator_matcher(";")])
                Function_type
            ])
        ])
        Function_args_with_return_type: sequence_matcher([
            list_matcher(Function_argument)
            optional_matcher(operator_matcher("?"))
            one_of_matcher([operator_matcher(":"), operator_matcher(";")])
            Type_element
        ])
        Function_definition: one_of_matcher([
            # fn_name(Args...): return_type
            #   Block_statements
            sequence_matcher([Function_declaration, Block])
            # (Args...): return_type
            #   Block_statements
            sequence_matcher([Function_args_with_return_type, Block])
            # fn_name(Args...): Statement
            sequence_matcher([
                Function_name 
                Function_args_with_return_type
                Rhs_statement
            ])
            # (Args...): Statement
            sequence_matcher([
                Function_args_with_return_type
                Rhs_statement
            ])
        ])
        Function_argument: one_of_matcher([
            Variable_definition
            Variable_declaration
            Function_definition
            Function_declaration
        ])
        Function_call: sequence_matcher([Function_name, Atomic_statement])
        # TODO: templates, or maybe preprocess these into snake_case types with hooks
        Function_type: sequence_matcher([
            optional_matcher(identifier_matcher("fn"))
            optional_matcher(Generics_list)
            Function_args_with_return_type
        ])
        Rhs_statement: one_of_matcher([
            Atomic_statement,
            sequence_matcher([Atomic_statement, Any_operator, Rhs_statement]),
        ])
        Atomic_statement: one_of_matcher([
            Variable_name
            Function_call
            parentheses_matcher(Rhs_statement)
            list_matcher(Defined_argument)
        ])
        Class_name: sequence_matcher([
            token snake_case
            optional_matcher(Template_arguments)
        ])
        Extend_parent_classes: sequence_matcher([
            keyword_matcher("extend")
            list_matcher(Class_name)
        ])
        Class_definition: sequence_matcher([
            Class_name
            one_of_matcher([
                operator_matcher(":")
                do_not_allow(operator_matcher(";"), "Classes cannot be writable.")
                do_not_allow(operator_matcher("?;"), "Classes cannot be nullable/writable.")
                do_not_allow(operator_matcher("?:"), "Classes cannot be nullable.")
            ])
            optional_matcher(Extend_parent_classes)
            parentheses_matcher(repeat_matcher([Class_statement], Until: operator_matcher("}")))
        ])
        Class_statement: one_of_matcher([
            Variable_definition
            Variable_declaration
            Function_definition
            Function_declaration
            Class_method
        ])
        Class_method: sequence_matcher([
            one_of_matcher([
                operator_matcher("::")
                operator_matcher(";;")
                operator_matcher(";:")
                operator_matcher(":;")
            ]),
            one_of_matcher([
                Function_definition
                Function_declaration
                # TODO: prefix ! and !!, as well as postfix !
            ])
        ])

        #(#
        # for-loops
        # e.g.
        for Variable: variable_type < Upper_bound_exclusive
            ... use Variable from 0 to ceil(Upper_bound_exclusive) - 1 ...
        # or
        for Variable: variable_type <= Upper_bound_inclusive
            ... use Variable from 0 to floor(Upper_bound_inclusive) ...
        # TODO: support starting value, or just variable names
        Variable; variable_type = 5
        for @lock Variable < Upper_bound_exclusive
            ... use Variable from 0 to ceil(Upper_bound_exclusive) - 1 ...
        # starting at number in the for loop
        for Variable: Starting_value, Variable < Upper_bound_exclusive
            ... use Variable from Starting_value ...
        #)#
        For_loop: one_of_matcher([
            sequence_matcher([
                # TODO: do we even need `keyword_matcher`, `identifier_matcher`, and `operator_matcher`?
                #       can't we just use `single_token_matcher` and be done with it?
                keyword_matcher("for")
                Variable_declaration
                one_of_matcher([operator_matcher("<"), operator_matcher("<=")])
                Expression
                Block
            ])
            sequence_matcher([
                keyword_matcher("for")
                list_matcher(Function_argument)
                keyword_matcher("in")
                Expression
                Block
            ])
        ])

        End_of_input: token_matcher(
            ::match(Index;, Array[token]): Index >= Array count()
        )
    ]

    ::match(Index;, Array[token], Grammar_matcher): bool
        # ensure being able to restore the current token index if we don't match:
        Snapshot: Index
        Matched: what Grammar_matcher
            (Token_matcher):
                Token_matcher match(Index;, Array)
            (Grammer_element):
                My Lot[Grammar_element] match(Index;, Array)
            (Token):
                Index < Array count() and Array[Index++] == Token
        if not Matched
            Index = Snapshot
        return Matched
}()

single_token_matcher: token_matcher (
    ;;renew(My Token): Null

    # we automatically inherit the @visibility of the parent class method
    # unless we specifically provide one.
    ;;match(Index;, Array[token]): bool
        return Index < Array count() and Array[Index++] == My Token
)

# TODO: actually compiling code will require going through the Token_matchers
# in a specific order to avoid running through all options to see what fits.
# OR, maybe we can parse a statement into tokens, and then do a `what Statement`
# with case `Rhs_statement` etc., where the hash only takes into account the sequence
# of tokens but not the actual token content.  we'd also need to ignore repeated fields,
# i.e., only count them once.
# TODO: support for labeling token matchers, e.g. "parent_class_names" and "class_block"
# or probably don't need to label token matchers if we build the logic for transpilation
# inside of the grammar elements.

# a list encompasses things like (), (Grammar_matcher), (Grammar_matcher, Grammar_matcher), etc.,
# but also lists with newlines if properly tabbed.
list_matcher(Grammar_matcher): parentheses_matcher(repeat_matcher([
    Grammar_matcher
    Comma_or_block_newline
])

sequence: token_matcher {
    ;;renew(My Array; grammar_matcher[]): Null

    ::match(Index;, To_match Array[token]): bool
        for Grammar_matcher: in My Array
            if not Grammar match(Index;, To_match Array, Grammar_matcher)
                return False
        return True
}

# TODO: add an argument to parentheses matcher for the type of parentheses, e.g., () [] {}
# TODO: make `block` a type of token as well.
parentheses_matcher: token_matcher {
    ;;renew(My Grammar_matcher): Null

    ::match(Index;, Array[token]): bool
        Current_token: Array[Index]
        if current_token != parentheses_token
            return False

        Internal_index; index = 0
        Partial_match: Grammar match(Internal_index;, Current_token Internal_tokens, My Grammar_matcher)
        if not Partial_match
            return False

        # need to ensure that the full content was matched inside the parentheses:
        if Internal_index < Current_token Internal_tokens count()
            return False
        
        ++Index
        return True
}

# TODO: make this a function which returns either `repeat_interruptible` and `repeat_times`
# this is essentially the definition for repeat_interruptible:
repeat_matcher: token_matcher {
    # until `Until` is found, checks matches through `Array` repeatedly.
    # note that `Until` can be found at any point in the array;
    # i.e., breaking out of the array early (after finding `Until`) still counts as a match.
    # if you need to ensure a non-breakable sequence is found before `Until`,
    # use the `sequence` token matcher inside `Array`.
    i(My Until: Grammar_matcher = End_of_input, My Array: Grammar_matcher[]): i()
    ;;renew(My Until: Grammar_matcher = End_of_input, My Array[grammar_matcher]): Null

    ::match(Index;, To_match Array[token]): bool
        if Index >= Array count()
            return False

        while True
            # TODO: is there a better syntax here that doesn't put `X: x` in front of `in`?
            #       it'd be nice to avoid parentheses if necessary, although that does make it clear
            #       that we have reference-like abilities.
            #       maybe `in My Array, Grammar_matcher:` or `iterate My Array, Grammar_matcher:`
            #           or `with My Array, Grammar_matcher:`
            #       or `for Grammar_matcher:, in My Array`
            for Grammar_matcher: in My Array
                # always check the escape sequence, Until:
                if Grammar match(Index;, To_match Array, My Until)
                    return True
                # note that it's ok to call `Grammar` here despite
                # the self-referential nature of the grammar, because
                # this logic would essentially be written in a .cc file
                # whereas `Grammar` would be defined in the .h file.
                if not Grammar match(Index;, Grammar_matcher)
                    return False
}
